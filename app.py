# ==========================================================
# ğŸ“š Multi-Language Audiobook & Text Processor (Final Version)
# ==========================================================

import streamlit as st
import docx
import fitz  # PyMuPDF for PDF reading
import tempfile
import os
from gtts import gTTS
import base64

# ===================== Optional Dependencies =====================
try:
    import nltk
    nltk.download('punkt')
    from nltk.tokenize import word_tokenize
    NLTK_AVAILABLE = True
except:
    NLTK_AVAILABLE = False

# ===================== Utility Functions =====================

def extract_text(file):
    """Extract text from TXT, DOCX, or PDF file."""
    name = file.name.lower()

    if name.endswith(".txt"):
        return file.read().decode("utf-8", errors="ignore")

    elif name.endswith(".docx"):
        doc = docx.Document(file)
        return "\n".join([p.text for p in doc.paragraphs])

    elif name.endswith(".pdf"):
        # Save PDF temporarily to read using fitz
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(file.read())
            tmp_path = tmp.name

        text = ""
        pdf = fitz.open(tmp_path)
        for page in pdf:
            text += page.get_text("text") or ""
        pdf.close()
        os.remove(tmp_path)
        return text

    else:
        raise ValueError("âŒ Unsupported file type. Please upload txt, docx, or pdf.")


def tokenize_text(text):
    """Tokenize text into words using NLTK or fallback split."""
    if NLTK_AVAILABLE:
        return word_tokenize(text)
    else:
        return text.split()


def chunk_text(text, chunk_size=3000, overlap=200):
    """Split text into overlapping chunks for TTS."""
    words = text.split()
    chunks = []
    i = 0
    while i < len(words):
        chunk = words[i:i + chunk_size]
        chunks.append(" ".join(chunk))
        i += chunk_size - overlap
    return chunks


def generate_tts(text, lang="en"):
    """Convert text into MP3 using gTTS and return the file path."""
    tts = gTTS(text, lang=lang)
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tts.save(tmp.name)
    return tmp.name

# ===================== Streamlit UI =====================

st.set_page_config(
    page_title="ğŸ“š Multi-Language Audiobook & Text Processor",
    layout="centered"
)

st.title("ğŸ“š Multi-Language Audiobook & Text Processor")
st.caption("Upload your document â†’ Tokenize â†’ Chunk â†’ Generate Audio ğŸ§")

# ---------- Upload Section ----------
uploaded_file = st.file_uploader("ğŸ“¤ Upload a text / pdf / docx file", type=["txt", "pdf", "docx"])

# ---------- Parameters ----------
st.markdown("### âš™ï¸ Settings")
chunk_size = st.number_input("Chunk size (words)", min_value=500, max_value=8000, value=2000, step=500)
overlap = st.number_input("Chunk overlap (words)", min_value=0, max_value=500, value=200, step=50)
tts_lang = st.selectbox("ğŸ§ Select Audio Language", ["en", "hi", "fr", "es"])

# ===================== MAIN LOGIC =====================

if uploaded_file:
    text = extract_text(uploaded_file)

    # --- Preview Text ---
    st.subheader("ğŸ“œ Original Text Preview")
    st.text_area("", text[:2000], height=200)

    # --- Tokenization ---
    st.subheader("ğŸ”  Tokenization")
    tokens = tokenize_text(text)
    st.write(f"**Total Tokens:** {len(tokens)}")
    st.write(tokens[:50])  # Show first few tokens

    # --- Chunking ---
    st.subheader("âœ‚ï¸ Text Chunking")
    chunks = chunk_text(text, chunk_size, overlap)
    st.write(f"**Total Chunks:** {len(chunks)}")
    st.write(chunks[0][:500] + "..." if chunks else "âš ï¸ No chunks found.")

    # --- Audio Generation ---
    if st.button("ğŸ§ Generate Audiobook"):
        with st.spinner("ğŸ¤ Generating audio, please wait..."):
            for i, c in enumerate(chunks, 1):
                audio_path = generate_tts(c, lang=tts_lang)
                st.audio(audio_path)  # Play audio in the app

                # Provide download link
                with open(audio_path, "rb") as f:
                    b64 = base64.b64encode(f.read()).decode()
                    href = f'<a href="data:audio/mp3;base64,{b64}" download="chunk_{i}.mp3">ğŸ“¥ Download Chunk {i}</a>'
                    st.markdown(href, unsafe_allow_html=True)

        st.success("âœ… Audiobook generation completed successfully!")

else:
    st.info("ğŸ“‚ Please upload a file to begin.")







# ============================================================
# ğŸŒ + ğŸ”Š MULTI-LANGUAGE TRANSLATOR & AUDIOBOOK GENERATOR (v3.1 FIXED)
# ============================================================

import streamlit as st
from deep_translator import GoogleTranslator
from gtts import gTTS
from datetime import datetime
import tempfile
import base64
import os

# âœ… Page setup
st.set_page_config(page_title="Translator + Audiobook Generator", page_icon="ğŸŒ")
st.title("ğŸŒ + ğŸ”Š Multi-Language Translator & Audiobook Generator")

# âœ… Supported languages
lang_dict = {
    "Hindi": "hi", "Bengali": "bn", "Tamil": "ta", "Telugu": "te",
    "Gujarati": "gu", "Malayalam": "ml", "Kannada": "kn", "Marathi": "mr",
    "Urdu": "ur", "English": "en",
    "Chhattisgarhi (Experimental)": "hne"
}

# âœ… Initialize session state
if "translated_text" not in st.session_state:
    st.session_state.translated_text = ""

# ============================================================
# ğŸŒ TEXT TRANSLATION SECTION
# ============================================================
st.header("ğŸŒ Step 1: Translate Your Text")

# âœ… Text input
text_input = st.text_area("âœï¸ Enter text to translate", 
                          "Type or paste English text here...", height=150)

# âœ… Language selection
target_lang = st.selectbox("ğŸŒ Choose Target Language", list(lang_dict.keys()), index=0)

# âœ… Translate button
if st.button("ğŸ” Translate Text"):
    if not text_input.strip():
        st.warning("âš ï¸ Please enter some text to translate.")
    else:
        try:
            translated_text = GoogleTranslator(source='auto', target=lang_dict[target_lang]).translate(text_input)
            st.session_state.translated_text = translated_text  # âœ… Store in session
            st.success(f"âœ… Translated Text ({target_lang}):")
            st.markdown(f"```\n{translated_text}\n```")
        except Exception as e:
            st.error(f"âŒ Translation Error: {e}")

# ============================================================
# ğŸ”Š AUDIOBOOK GENERATION SECTION
# ============================================================
st.header("ğŸ§ Step 2: Generate Audio from Translated Text")

if not st.session_state.translated_text:
    st.info("â„¹ï¸ Please translate your text first to enable audio generation.")

if st.button("ğŸ™ï¸ Generate Audio"):
    if not st.session_state.translated_text.strip():
        st.warning("âš ï¸ Please translate some text first.")
    else:
        try:
            translated_text = st.session_state.translated_text
            st.write(f"ğŸ§ Generating audio in **{target_lang}** ...")
            tts = gTTS(translated_text, lang=lang_dict[target_lang])

            # Save with timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_name = f"translated_audio_{target_lang}_{timestamp}.mp3"
            audio_path = os.path.join(tempfile.gettempdir(), file_name)
            tts.save(audio_path)

            # Play audio
            st.audio(audio_path, format='audio/mp3', start_time=0)

            # Download link
            with open(audio_path, "rb") as f:
                audio_bytes = f.read()
            b64 = base64.b64encode(audio_bytes).decode()
            href = f'<a href="data:audio/mp3;base64,{b64}" download="{file_name}" style="text-decoration:none;"><button style="background-color:#4CAF50;color:white;padding:10px 15px;border:none;border-radius:8px;cursor:pointer;">â¬‡ï¸ Download {target_lang} Audio</button></a>'
            st.markdown(href, unsafe_allow_html=True)

        except Exception as e:
            st.error(f"âŒ Error generating audio: {e}")



















 # ============================================================
# ğŸŒ Universal Translator + Audiobook Generator (Streamlit)
# ============================================================

import streamlit as st
import os
import tempfile
from gtts import gTTS
from deep_translator import GoogleTranslator
import PyPDF2
import docx
from odf.opendocument import load
from odf import text, teletype
from datetime import datetime

# -------------------------------
# ğŸŒ Supported Languages
# -------------------------------
languages = {
    "en": "English",
    "hi": "Hindi",
    "bn": "Bengali",
    "ta": "Tamil",
    "te": "Telugu",
    "mr": "Marathi",
    "gu": "Gujarati",
    "kn": "Kannada",
    "ml": "Malayalam",
    "pa": "Punjabi",
    "or": "Odia",
    "ur": "Urdu",
    "ne": "Nepali",
    "bho": "Bhojpuri (via Hindi)",
    "cg": "Chhattisgarhi (via Hindi)"
}

# -------------------------------
# Streamlit UI
# -------------------------------
st.set_page_config(page_title="Universal Translator + Audiobook", page_icon="ğŸ§")
st.title("ğŸŒ Universal Translator + Audiobook Generator")
st.markdown("Upload a file (TXT, PDF, DOCX, ODT), translate it to your chosen language, and generate audio!")

uploaded_file = st.file_uploader("ğŸ“‚ Upload File", type=["txt", "pdf", "docx", "odt"])
target_lang = st.selectbox("ğŸ¯ Select Target Language", list(languages.values()))

# -------------------------------
# Extract Text
# -------------------------------
def extract_text(file):
    ext = os.path.splitext(file.name)[1].lower()
    text_content = ""

    if ext == ".txt":
        text_content = str(file.read(), "utf-8")
    elif ext == ".pdf":
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            text_content += page.extract_text() or ""
    elif ext == ".docx":
        doc = docx.Document(file)
        for para in doc.paragraphs:
            text_content += para.text + "\n"
    elif ext == ".odt":
        doc = load(file)
        allparas = doc.getElementsByType(text.P)
        for para in allparas:
            text_content += teletype.extractText(para) + "\n"
    else:
        st.error("âŒ Unsupported file type!")
    return text_content.strip()

# -------------------------------
# Map language name â†’ code
# -------------------------------
def get_lang_code(lang_name):
    lang_name = lang_name.lower()
    # Custom mappings
    if lang_name in ["bhojpuri", "bhojpuri (via hindi)", "bho"]:
        return "hi"
    if lang_name in ["chhattisgarhi", "chhattisgarhi (via hindi)", "cg"]:
        return "hi"
    # normal case
    for code, name in languages.items():
        if name.lower() == lang_name:
            return code
    return "en"  # default English

# -------------------------------
# Process File
# -------------------------------
if uploaded_file:
    try:
        extracted_text = extract_text(uploaded_file)
        if not extracted_text:
            st.warning("âš ï¸ No text found in file.")
            st.stop()

        st.subheader("ğŸ“– Extracted Text")
        st.write(extracted_text[:2000] + ("..." if len(extracted_text) > 2000 else ""))

        target_code = get_lang_code(target_lang)

        # -------------------------------
        # Translate paragraph by paragraph
        # -------------------------------
        st.info("ğŸ”„ Translating text...")
        try:
            paragraphs = [p for p in extracted_text.split("\n") if p.strip() != ""]
            translated_paragraphs = []
            for para in paragraphs:
                try:
                    translated_para = GoogleTranslator(source='auto', target=target_code).translate(para)
                except Exception:
                    translated_para = para  # fallback if translation fails
                translated_paragraphs.append(translated_para)
            translated_text = "\n".join(translated_paragraphs)
            st.success("âœ… Translation Complete!")
        except Exception as e:
            st.error(f"âŒ Translation Failed: {e}")
            translated_text = extracted_text  # fallback: original text

        st.subheader(f"ğŸŒ Translated Text ({target_lang})")
        st.write(translated_text[:2000] + ("..." if len(translated_text) > 2000 else ""))

        # -------------------------------
        # Generate TTS Audio
        # -------------------------------
        st.info("ğŸ§ Generating audio...")
        try:
            tts = gTTS(translated_text, lang=target_code)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            audio_filename = f"translated_audio_{target_lang}_{ts}.mp3"
            audio_path = os.path.join(tempfile.gettempdir(), audio_filename)
            tts.save(audio_path)
            st.success("âœ… Audio Generated!")

            # Play Audio
            st.audio(audio_path)

            # Download Audio
            with open(audio_path, "rb") as f:
                st.download_button(
                    label="ğŸ’¾ Download Audio (MP3)",
                    data=f,
                    file_name=audio_filename,
                    mime="audio/mp3"
                )
        except Exception as e:
            st.error(f"âŒ TTS Generation Failed: {e}")

        # Download Translated Text
        text_filename = f"translated_text_{target_lang}_{ts}.txt"
        text_path = os.path.join(tempfile.gettempdir(), text_filename)
        with open(text_path, "w", encoding="utf-8") as f:
            f.write(translated_text)
        with open(text_path, "rb") as f:
            st.download_button(
                label="ğŸ’¾ Download Translated Text",
                data=f,
                file_name=text_filename,
                mime="text/plain"
            )

    except Exception as e:
        st.error(f"âŒ Error: {e}")







import streamlit as st
from transformers import pipeline
from deep_translator import GoogleTranslator
import torch

# --------- Setup ---------
device = 0 if torch.cuda.is_available() else -1

st.set_page_config(page_title="ğŸŒŸ Emotion Detector", page_icon="ğŸ˜„")
st.title("ğŸ˜„ Emotion Detection + Multi-language Support")
st.markdown("Enter text in any language, and detect the dominant emotion with explanation.")

# Load model
@st.cache_resource(show_spinner=True)
def load_emotion_model():
    return pipeline(
        "text-classification",
        model="j-hartmann/emotion-english-distilroberta-base",
        return_all_scores=True,
        device=device
    )

emotion_classifier = load_emotion_model()
translator = GoogleTranslator(source='auto', target='en')

# --------- Function to detect emotion ---------
def detect_emotion(text):
    if not text.strip():
        st.warning("âš ï¸ Empty text!")
        return

    # Translate text to English
    text_en = translator.translate(text)
    st.markdown(f"ğŸŒ **Translated to English:** {text_en}")

    # Split text into chunks of 500 characters
    chunks = [text_en[i:i+500] for i in range(0, len(text_en), 500)]
    combined_scores = {}

    for chunk in chunks:
        result = emotion_classifier(chunk)[0]
        for r in result:
            combined_scores[r['label']] = combined_scores.get(r['label'], 0) + r['score']

    # Average scores
    for k in combined_scores:
        combined_scores[k] /= len(chunks)

    # Sort & get dominant emotion
    sorted_scores = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)
    label, score = sorted_scores[0]

    mood_map = {
        "joy": "ğŸ˜Š You seem happy and content.",
        "sadness": "ğŸ˜¢ You sound sad or reflective.",
        "anger": "ğŸ˜¡ You might be feeling angry or frustrated.",
        "fear": "ğŸ˜¨ Thereâ€™s some fear or anxiety in your tone.",
        "love": "â¤ï¸ Youâ€™re expressing affection or care.",
        "surprise": "ğŸ˜² Thereâ€™s surprise or shock in your tone.",
        "disgust": "ğŸ¤¢ Thereâ€™s dislike or rejection in your words.",
        "neutral": "ğŸ˜ Your tone feels calm and neutral."
    }

    mood_summary = mood_map.get(label.lower(), "ğŸ™‚ General emotion detected.")
    
    st.subheader(f"ğŸ¯ Dominant Emotion: {label} (confidence: {score:.3f})")
    st.info(mood_summary)

    st.subheader("ğŸ“Š All emotions ranked:")
    for lbl, scr in sorted_scores:
        st.write(f"- {lbl:<10}: {scr:.3f}")

# --------- User Input ---------
user_text = st.text_area("ğŸ“ Enter your text (any language):", height=150)

if st.button("Detect Emotion"):
    detect_emotion(user_text)

      


# ============================================================
# ğŸ“ FOOTER
# ============================================================
st.markdown("---")
st.markdown("ğŸ’¡ *Developed by Aman | Powered by Deep Translator + gTTS*")
